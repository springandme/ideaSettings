<application>
  <component name="AppStorage">
    <histories>
      <item value="emit" />
      <item value="Emit" />
      <item value="Emits a record." />
      <item value="which &quot;pulls&quot; data in." />
      <item value="Collects a record and forwards it. The collector is the &quot;push&quot; counterpart of the" />
      <item value="This is a shortcut for either `.window(SlidingEventTimeWindows.of(size))` or * `.window(SlidingProcessingTimeWindows.of(size))` depending on the time characteristic * set using" />
      <item value="Windows this [[KeyedStream]] into sliding time windows." />
      <item value="slide" />
      <item value="Windows this [[KeyedStream]] into tumbling time windows." />
      <item value="This is a shortcut for either `.window(TumblingEventTimeWindows.of(size))` or * `.window(TumblingProcessingTimeWindows.of(size))` depending on the time characteristic * set using * [[StreamExecutionEnvironment.setStreamTimeCharacteristic()]]" />
      <item value="sensor" />
      <item value="tumble" />
      <item value="tumbling" />
      <item value="the first parameter is 1, the second is 2, ..." />
      <item value="Properties with the producer configuration." />
      <item value="User defined key-less serialization schema." />
      <item value="The SplitStream represents an operator that has been split using an * [[org.apache.flink.streaming.api.collector.selector.OutputSelector]]. * Named outputs can be selected using the [[SplitStream#select()]] function. * To apply a transformation on the whole output simply call * the appropriate method on this stream." />
      <item value="Sets the output names for which the next operator will receive values." />
      <item value="偶数" />
      <item value="Creates a new ConnectedStreams by connecting * DataStream outputs of different type with each other. The * DataStreams connected using this operators can be used with CoFunctions." />
      <item value="Cancels the source. Most sources will have a while loop inside the * {@link #run(SourceContext)} method. The implementation needs to ensure that the * source will break out of that loop after this method is called." />
      <item value="&lt;p&gt;Sources that implement {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction} * must lock on the checkpoint lock (using a synchronized block) before updating internal * state and emitting elements, to make both an atomic operation:" />
      <item value="Starts the source. Implementations can use the {@link SourceContext} emit * elements." />
      <item value="Groups the elements of a DataStream by the given key positions (for tuple/array types) to * be used with grouped operators like grouped reduce or grouped aggregations." />
      <item value="he de-/serializer used to convert between Kafka's byte messages and Flink's objects." />
      <item value="Creates a new Kafka streaming source consumer for Kafka 0.10.x" />
      <item value="Creates a new Kafka streaming source consumer for Kafka 0.10.x." />
      <item value="Base class for implementing a parallel data source that has access to context information" />
      <item value="the minimum time to sleep. If less than * or equal to zero, do not sleep at all." />
      <item value="Performs a {@link Thread#sleep(long, int) Thread.sleep} using * this time unit. * This is a convenience method that converts time arguments into the * form required by the {@code Thread.sleep} method." />
      <item value="Returns a pseudorandom, uniformly distributed int value between 0 * (inclusive) and the specified value (exclusive), drawn from this * random number generator's sequence." />
      <item value="The object `Random` offers a default implementation * of scala.util.Random and random-related convenience methods." />
      <item value="金额" />
      <item value="Creates a new DataStream that contains the strings received infinitely * from socket. Received strings are decoded by the system's default * character set. The maximum retry interval is specified in seconds, in case * of temporary service outage reconnection is initiated every second." />
      <item value="Sets the parallelism for operations executed through this environment. * Setting a parallelism of x here will cause all operators (such as join, map, reduce) to run * with x parallel instances. This value can be overridden by specific operations using * [[DataStream#setParallelism(int)]]." />
      <item value="Rich variant of the {@link MapFunction}. As a {@link RichFunction}, it gives access to the" />
      <item value="gracefully" />
      <item value="Creates a local execution environment. The local execution environment will run the * program in a multi-threaded fashion in the same JVM as the environment was created in. * * This method sets the environment's default parallelism to given parameter, which * defaults to the value set via [[setDefaultLocalParallelism(Int)]]." />
      <item value="execute" />
      <item value="execution" />
      <item value="执行" />
      <item value="Triggers the program execution. The environment will execute all parts of the program that have * resulted in a &quot;sink&quot; operation. Sink operations are for example printing results * [[DataSet.print]], writing results (e.g. [[DataSet.writeAsText]], [[DataSet.write]], or other * generic data sinks created with [[DataSet.output]]." />
      <item value="No data sinks have been created yet. A program needs at least one sink that consumes data. Examples are writing the data set or printing it." />
      <item value="Creates a new target file regardless of any existing files or directories. * Existing files and directories will be deleted (recursively) automatically before * creating the new file. */" />
      <item value="Creates the target file only if no file exists at that path already. * Does not overwrite existing files and directories. */" />
      <item value="Sets the parallelism of this operation. This must be greater than 1." />
      <item value="输出" />
      <item value="Indicates an order without a direction. This constant is not used to indicate * any existing order, but for example to indicate that an order of any direction * is desirable." />
      <item value="Indicates no order." />
      <item value="Partitions a DataSet using the specified key selector function. * * '''Important:'''This operation shuffles the whole DataSet over the network and can take * significant amount of time." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="527" />
        <entry key="ENGLISH" value="527" />
        <entry key="ARABIC" value="1" />
        <entry key="FRENCH" value="3" />
        <entry key="LATIN" value="2" />
        <entry key="LITHUANIAN" value="1" />
        <entry key="LUXEMBOURGISH" value="1" />
        <entry key="JAPANESE" value="10" />
        <entry key="SWEDISH" value="1" />
        <entry key="WELSH" value="3" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
    <option name="phoneticFontFamily" value="Consolas" />
    <option name="primaryFontFamily" value="Consolas" />
  </component>
</application>