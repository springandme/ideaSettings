<application>
  <component name="AppStorage">
    <histories>
      <item value="Sets the parallelism for operations executed through this environment. * Setting a parallelism of x here will cause all operators (such as join, map, reduce) to run * with x parallel instances. This value can be overridden by specific operations using * [[DataStream#setParallelism(int)]]." />
      <item value="Rich variant of the {@link MapFunction}. As a {@link RichFunction}, it gives access to the" />
      <item value="gracefully" />
      <item value="Creates a local execution environment. The local execution environment will run the * program in a multi-threaded fashion in the same JVM as the environment was created in. * * This method sets the environment's default parallelism to given parameter, which * defaults to the value set via [[setDefaultLocalParallelism(Int)]]." />
      <item value="execute" />
      <item value="execution" />
      <item value="执行" />
      <item value="Triggers the program execution. The environment will execute all parts of the program that have * resulted in a &quot;sink&quot; operation. Sink operations are for example printing results * [[DataSet.print]], writing results (e.g. [[DataSet.writeAsText]], [[DataSet.write]], or other * generic data sinks created with [[DataSet.output]]." />
      <item value="No data sinks have been created yet. A program needs at least one sink that consumes data. Examples are writing the data set or printing it." />
      <item value="Creates a new target file regardless of any existing files or directories. * Existing files and directories will be deleted (recursively) automatically before * creating the new file. */" />
      <item value="Creates the target file only if no file exists at that path already. * Does not overwrite existing files and directories. */" />
      <item value="Sets the parallelism of this operation. This must be greater than 1." />
      <item value="输出" />
      <item value="Indicates an order without a direction. This constant is not used to indicate * any existing order, but for example to indicate that an order of any direction * is desirable." />
      <item value="Indicates no order." />
      <item value="Partitions a DataSet using the specified key selector function. * * '''Important:'''This operation shuffles the whole DataSet over the network and can take * significant amount of time." />
      <item value="wrap" />
      <item value="Enforces a re-balancing of the DataSet, i.e., the DataSet is evenly distributed over all * parallel instances of the * following task. This can help to improve performance in case of heavy data skew and compute * intensive operations. * * '''Important:''' This operation shuffles the whole DataSet over the network and can take * significant amount of time. * * @return The rebalanced DataSet." />
      <item value="An enumeration of hints, optionally usable to tell the system how exactly execute the join." />
      <item value="Special [[join]] operation for explicitly telling the system what join strategy to use. If * null is given as the join strategy, then the optimizer will pick the strategy." />
      <item value="If the input is a composite type (Tuple or Pojo type), distinct is performed on all fields * and each field must be a key type.&lt;/p&gt;" />
      <item value="Returns a distinct set of this DataSet." />
      <item value="Shortcuts for Aggregation factories." />
      <item value="Creates a [[GroupedDataSet]] which provides operations on groups of elements. Elements are * grouped based on the value returned by the given function. * * This will not create a new DataSet, it will just attach the key function which will be used * for grouping when executing a grouped operation." />
      <item value="Syntactic sugar for [[aggregate]] with `SUM`" />
      <item value="Creates a [[GroupedDataSet]] which provides operations on groups of elements. Elements are * grouped based on the given fields. * * This will not create a new DataSet, it will just attach the field names which will be * used for grouping when executing a grouped operation." />
      <item value="Creates a [[GroupedDataSet]] which provides operations on groups of elements. Elements are * grouped based on the given tuple fields. * * This will not create a new DataSet, it will just attach the tuple field positions which will be * used for grouping when executing a grouped operation. * * This only works on Tuple DataSets. */" />
      <item value="Creates a new [[DataSet]] by merging the elements of this DataSet using an associative reduce * function." />
      <item value="Creates a new DataSet by applying the given function to every element and flattening * the results." />
      <item value="遍历" />
      <item value="The fields in the file that should be read. Per default all fields * are read." />
      <item value="The fields of the POJO which are mapped to CSV fields." />
      <item value="Whether the parser should silently ignore malformed lines." />
      <item value="Lines that start with the given String are ignored, disabled by default." />
      <item value="The character to use for quoted String parsing, disabled by default." />
      <item value="The string that separates lines, defaults to newline." />
      <item value="ParserError NUMERIC_VALUE_FORMAT_ERROR" />
      <item value="Creates a new data set that contains a sequence of numbers. The data set will be created in * parallel, so there is no guarantee about the oder of the elements." />
      <item value="Note that this operation will result in a non-parallel data source, i.e. a data source with * a parallelism of one." />
      <item value="Creates a new data set that contains the given elements." />
      <item value="Creates a new [[StructType]] by adding a new nullable field with no metadata." />
      <item value="A row implementation that uses an array of objects as the underlying storage. Note that, while * the array is not copied, and thus could technically be mutated after creation, this is not * allowed." />
      <item value="This method can be used to construct a [[Row]] from a `Seq` of values." />
      <item value="No implicit arguments of type: Encoder[Row]" />
      <item value="分隔符" />
      <item value="specific " />
      <item value="This is declared with parentheses to prevent the Scala compiler from treating // `ds.toDF(&quot;1&quot;)` as invoking this toDF and then apply on the returned DataFrame." />
      <item value="Converts this strongly typed collection of data to generic Dataframe. In contrast to the * strongly typed objects that Dataset operations work on, a Dataframe returns generic [[Row]] * objects that allow fields to be accessed by ordinal or name." />
      <item value="Returns the value at position i of array type as a Scala Seq." />
      <item value="Checks whether the value at position i is null" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="494" />
        <entry key="ENGLISH" value="495" />
        <entry key="ARABIC" value="1" />
        <entry key="FRENCH" value="3" />
        <entry key="LATIN" value="2" />
        <entry key="LITHUANIAN" value="1" />
        <entry key="LUXEMBOURGISH" value="1" />
        <entry key="JAPANESE" value="10" />
        <entry key="SWEDISH" value="1" />
        <entry key="WELSH" value="3" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
    <option name="phoneticFontFamily" value="Consolas" />
    <option name="primaryFontFamily" value="Consolas" />
  </component>
</application>