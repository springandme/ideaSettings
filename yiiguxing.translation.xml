<application>
  <component name="AppStorage">
    <histories>
      <item value="broker" />
      <item value="定时" />
      <item value="slide" />
      <item value="mutable" />
      <item value="A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&amp;mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form &quot; + &quot;&lt;code&gt;host1:port1,host2:port2,...&lt;/code&gt;. Since these servers are just used for the initial connection to &quot; + &quot;discover the full cluster membership (which may change dynamically), this list need not contain the full set of &quot; + &quot;servers (you may want more than one, though, in case a server is down).&quot;;" />
      <item value="practice" />
      <item value="练习" />
      <item value="Additional context about the input record." />
      <item value="Writes the given value to the sink. This function is called for every record. * * &lt;p&gt;You have to override this method when implementing a {@code SinkFunction}, this is a * {@code default} method for backward compatibility with the old-style method only." />
      <item value="Interface for implementing user defined sink functionality." />
      <item value="intent" />
      <item value="Returns a pseudorandom, uniformly distributed int value between 0 * (inclusive) and the specified value (exclusive), drawn from this * random number generator's sequence." />
      <item value="随机" />
      <item value="Sets the field delimiter, &quot;,&quot; by default." />
      <item value="Sets the line delimiter, &quot;\n&quot; by default." />
      <item value="Encountered" />
      <item value="The write mode to specify whether existing files are overwritten or not." />
      <item value="numFiles The number of files to write to" />
      <item value="field Delim The field delimiter" />
      <item value="fieldDelim The field delimiter" />
      <item value="path The output path to write the Table to." />
      <item value="Registers the given [[DataStream]] as table in the * [[TableEnvironment]]'s catalog. * Registered tables can be referenced in SQL queries. * * The field names of the [[Table]] are automatically derived * from the type of the [[DataStream]]." />
      <item value="Time interval between state checkpoints in milliseconds." />
      <item value="Cancels the source. Most sources will have a while loop inside the * {@link #run(SourceContext)} method. The implementation needs to ensure that the * source will break out of that loop after this method is called." />
      <item value="A [[scala.collection.immutable.Range]] from `this` up to but * not including `end`." />
      <item value="coordinator" />
      <item value="Coordinator" />
      <item value="barrier" />
      <item value="Returns true, if state was restored from the snapshot of a previous execution. This returns always false for * stateless tasks." />
      <item value="snapshot State" />
      <item value="// If it hasn't been used before, it will be null" />
      <item value="emit" />
      <item value="Emit" />
      <item value="Emits a record." />
      <item value="which &quot;pulls&quot; data in." />
      <item value="Collects a record and forwards it. The collector is the &quot;push&quot; counterpart of the" />
      <item value="This is a shortcut for either `.window(SlidingEventTimeWindows.of(size))` or * `.window(SlidingProcessingTimeWindows.of(size))` depending on the time characteristic * set using" />
      <item value="Windows this [[KeyedStream]] into sliding time windows." />
      <item value="Windows this [[KeyedStream]] into tumbling time windows." />
      <item value="This is a shortcut for either `.window(TumblingEventTimeWindows.of(size))` or * `.window(TumblingProcessingTimeWindows.of(size))` depending on the time characteristic * set using * [[StreamExecutionEnvironment.setStreamTimeCharacteristic()]]" />
      <item value="sensor" />
      <item value="tumble" />
      <item value="tumbling" />
      <item value="the first parameter is 1, the second is 2, ..." />
      <item value="Properties with the producer configuration." />
      <item value="User defined key-less serialization schema." />
      <item value="The SplitStream represents an operator that has been split using an * [[org.apache.flink.streaming.api.collector.selector.OutputSelector]]. * Named outputs can be selected using the [[SplitStream#select()]] function. * To apply a transformation on the whole output simply call * the appropriate method on this stream." />
      <item value="Sets the output names for which the next operator will receive values." />
      <item value="偶数" />
      <item value="Creates a new ConnectedStreams by connecting * DataStream outputs of different type with each other. The * DataStreams connected using this operators can be used with CoFunctions." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="549" />
        <entry key="ENGLISH" value="549" />
        <entry key="ARABIC" value="1" />
        <entry key="FRENCH" value="3" />
        <entry key="LATIN" value="2" />
        <entry key="LITHUANIAN" value="1" />
        <entry key="LUXEMBOURGISH" value="1" />
        <entry key="JAPANESE" value="10" />
        <entry key="SWEDISH" value="1" />
        <entry key="WELSH" value="3" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
    <option name="phoneticFontFamily" value="Consolas" />
    <option name="primaryFontFamily" value="Consolas" />
  </component>
</application>